# -*- coding: utf-8 -*-
"""SlogansGen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12MKolvsW7Nlsj66Czwgx9SfdTHR-Nvkk
"""

# ðŸ“¦ Installations nÃ©cessaires
!pip install transformers tensorflow --quiet

# ðŸ“š Imports
import pandas as pd
import random
import numpy as np
from collections import defaultdict
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch

# ðŸ“‚ Chargement du dataset
df = pd.read_csv('slogans.csv')

# ðŸ‘‰ VÃ©rifier les noms de colonnes du DataFrame
print(df.columns)

# ðŸ‘‰ Remplacer 'slogan' par le nom correct de la colonne
#    contenant les slogans, par exemple 'Slogan' ou 'Text'
slogans = df['Slogan'].dropna().astype(str).tolist() # or df['Text'] or... depending on your csv


# âœ… 1. N-grammes (Bigrammes simples)
def generate_ngram_text(slogans, n=2, length=10):
    model = defaultdict(list)
    for line in slogans:
        tokens = line.split()
        for i in range(len(tokens) - 1):
            model[tokens[i]].append(tokens[i + 1])
    word = random.choice(list(model.keys()))
    result = [word]
    for _ in range(length):
        next_words = model.get(word)
        if not next_words:
            break
        word = random.choice(next_words)
        result.append(word)
    return ' '.join(result)

print("ðŸ”¸ N-gramme :", generate_ngram_text(slogans))

# âœ… 2. RNN (Recurrent Neural Network)
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(slogans)
total_words = len(tokenizer.word_index) + 1

input_sequences = []
for line in slogans:
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

max_sequence_len = max([len(seq) for seq in input_sequences])
input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')
xs, labels = input_sequences[:, :-1], input_sequences[:, -1]
ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)

model = Sequential()
model.add(Embedding(total_words, 10, input_length=max_sequence_len - 1))
model.add(LSTM(100))
model.add(Dense(total_words, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')
model.fit(xs, ys, epochs=10, verbose=0)

def generate_rnn_text(seed_text, next_words=5):
    for _ in range(next_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')
        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)[0]
        output_word = ""
        for word, index in tokenizer.word_index.items():
            if index == predicted:
                output_word = word
                break
        seed_text += " " + output_word
    return seed_text

print("ðŸ”¸ RNN :", generate_rnn_text("Experience"))

# âœ… 3. GPT-2 (Transformer avec fine-tuning si souhaitÃ©)
tokenizer_gpt2 = GPT2Tokenizer.from_pretrained("gpt2")
model_gpt2 = GPT2LMHeadModel.from_pretrained("gpt2")

def generate_gpt2(prompt, max_length=30):
    inputs = tokenizer_gpt2(prompt, return_tensors="pt")
    outputs = model_gpt2.generate(inputs['input_ids'], max_length=max_length, do_sample=True, temperature=0.9)
    return tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True)

print("ðŸ”¸ GPT-2 :", generate_gpt2("Discover the taste of"))

!pip install --upgrade openai

import getpass
import openai

api_key = getpass.getpass("Enter your OpenAI API key: ")
client = openai.OpenAI(api_key=api_key)

import time
import openai

def generate_gpt_slogan(prompt):
    # Wait for a longer time  before making the API call
    time.sleep(5)  # Increased delay to 5 seconds
    chat_completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return chat_completion.choices[0].message.content.strip()

# Exemple :
prompt = "Propose un slogan original pour une marque de cafÃ© tunisienne."
slogan = generate_gpt_slogan(prompt)
print("ðŸ§  GPT-3.5 generated slogan:", slogan)